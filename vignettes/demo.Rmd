---
title: "demo"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{demo}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(gristmill)
```


Whereas base R only has the `ecdf()` function to handle empirical distributions, distplyr provides full functionality with `dst_empirical()`. Empirical distribution of `hp` values in the `mtcars` dataset:

```{r}
(hp <- dst_empirical(hp, data = mtcars))
```

The "step" in the name comes from the cdf:

```{r, fig.width = 4, fig.height = 3}
plot(hp, "cdf", n = 501)
```

You can also weigh the outcomes differently. This is useful for explicitly specifying a probability mass function, as well as for other applications such as using kernel smoothing to find a conditional distribution. Here is an estimate of the conditional distribution of `hp` given `disp = 150`, with cdf depicted as the dashed line compared o the marginal with the solid line:

```{r}
K <- function(x) dnorm(x, sd = 25)
hp2 <- dst_empirical(hp, data = mtcars, weights = K(disp - 150))
plot(hp, "cdf", n = 1001)
plot(hp2, "cdf", n = 1001, lty = 2, add = TRUE)
```

The weighting provides us with a far more informative prediction of `hp` when `disp = 150` compared to the loess, which just gives us the mean:

```{r}
mean(hp2)
```

With a distribution, you can get much more, such as this 90% prediction interval:

```{r}
eval_quantile(hp2, at = c(0.05, 0.95))
```

Here's the proportion of variance that's reduced compared to the marginal:

```{r}
1 - variance(hp2) / variance(hp)
```
